
\section{Introduction}\label{sec:3.1}
\vspace{-0.5cm}
\noindent This chapter provides a review of the well-known algorithms of image segmentation, pattern recognition, exhaustive search and deep learning methods.We will also explain how the main image segmentation methods work and how they developed in computer vision. Also will demonstrated methods forward and backpropagation. Between this two process, you can see the optimization process, which try to minimize function of error. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Computer Vision and Pattern Recognition} \label{sec:3.2}
\vspace{-0.5cm}
\noindent For a person, the perception of the outside world with your own eyes is a very simple task, be looking at any 2- or 3-dimensional object, you can safely tell about its shape and external structure.Looking at the crowd of people, the human brain can easily calculate the number of objects, can tell about their shape and condition. But what about the computer? Will the computer be able to handle the processing of objects that people see? Will the computer be able to find the difference between very similar objects? In this matter will help discipline called computer vision.This area is very closely related to signal processing, image processing, and video recording. As well as it includes machine learning with pattern recognition.Along with other Sciences like text processing and audio processing, science tries to create the ideal artificial intelligence that can think and act like a human.Image processing not only includes the transformation of images into a more comfortable and desired type but also this area along with computer vision will be able to show what is inside the image. Image processing not only includes the transformation of images into a more comfortable and desired look but also this area along with computer vision will be able to show what is inside the image. Also, this area helps in capturing movements inside the picture.[CVPR]
Understanding what exactly is happening on images and perception of this process is an important process in AI. Draw conclusions depending on what you see is a fairly simple process for a person, but not for the computer. Since a computer without any reason cannot understand the essence of the process. The problem in object recognition is the appearance of these objects in new forms or compositions because the pre-built model cannot cope with it, because it has not seen the object in this format. These new formats can be represented as an object in the expanded state, or it can be simply in motion. A huge number of new forms and aspects makes the object recognition a practically impossible task.[introTOCV]
%\vspace{-0.5cm}
%\par 

%\vspace{-0.5cm}
%\noindent 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Selective Search}\label{sec:3.3}
\vspace{-0.5cm}
\noindent Exhaustive search helps to find parts of the image where you want to consider the potential parts of the desired object.Although this model works well with specially selected objects, it has a number of drawbacks that significantly affect the detection of logos.After all, the search for every possible object has the ability to be impossible. To solve this, we can use selective search.To improve the whole process and the data set for testing, we can use a combined method where we will use both methods described above. Since the number of possible objects will be more and less real and possible.Diversity in this task plays an important role, as we can cover more and more possible variants of this logo in the image.Since selective search is more useful to us, it will be helpful to familiarize yourself with its dependencies.The first and most important factor is to cover as many scales as possible because the logo can be small or large. We may not warn that. After all, the situation can be quite different. Also can make problems of objects which have no clear borders, for this reason, it is necessary to look through all options of the sizes of an object.Also, it should be noted that there is no exact and general solution of searches of any objects. It is impossible to make such a general detection system. Well, at the moment of course. For this reason, you should also look at the variety of objects and their contours, which can be very important in training. Speed is an important factor when searching for possible objects in an image. After all, such systems are built to determine the objects on the camera in a short period of time.This method is exclusive in that it is possible to configure this so that it worked by concentrating on the object and not on its borders.[ssForSegmentation]

\section{Image Segmentation Methods}\label{sec:3.4}
\vspace{-0.5cm}
\noindent In practice, the importance and value is not always fully the image itself, namely what are the specific parts of the image, and sometimes just the number of channels of the image.The first and one of the most important technologies for understanding what is happening inside this image is segmentation.Since only a segmentation can be divided into important and different parts.After all, it helps to understand the image inside the image, as well as to extract useful information for us.  These aspects are extremely important for programs where image recognition is paramount.For all these reasons, it can be understood that segmentation is a very important discipline within computer vision, and in turn, segmentation has a huge number of difficulties in implementing many methods.In short, segmentation is important for recognition, because it can pull out those areas that are very important for humans. And are the basis for all methods of recognition of contours and objects.There are many types of segmentation and a huge number of places where you can use them.One of the most common methods is threshold segmentation.The basis of this algorithm creates a segmentation of the image by its regions.This method searches for a threshold by a specific criterion to create a grayscale that will be distributed from other colors. This method sets a specific threshold for pixels and depending on the condition they change from 0 to 255 in grayscale.You can also mark a method called edge segmentation. This method is particularly the fact that he refers to the saturation of gray on the borders of any object.In the discipline of computer vision and related industries, there is no single segmentation method that can work in all cases. To use the segmentation method correctly, you need to consider the advantages and disadvantages. After all, each method will lead in different ways depending on the situation and the state in the image. And it is also very important to apply the correct parameters of segmentation methods. Since the parameters play a significant role in the algorithm.[1707.02051]

\vspace{-0.5cm}
\par
\noindent Segmentation, by itself, is splitting the image into several areas, depending on their structure, size, and saturation of any particular colors. These areas can include grouped pixels, which represent the object itself, and can represent a variety of shapes, such as an arc, circle, or just a line. Developed regions can be simple lines or full-fledged objects that can have boundaries separating them from other content. Since the area of interest may not cover the entire image, we are interested in using segmentation in such cases. Segmentation has two main goals that it pursues. The first is to expand the image to the desired regions. The second task is to change the representation.Considering the simplest cases, when the interesting part of the image is very different from the rest, the segmentation will not be a problem. After all, the area of our interest, especially its color and saturation help to clearly separate it from the rest of the image. After all, the rest of the area does not have similar components as in the desired image area.But there are also severe cases where the boundaries are strongly distorted and erased as the color saturation is very similar, and the components do not differ from each other.Considering the second objective pursued by the segmentation can be sure it will ultimately give us a richer and more precise representation of the object within the image. Here our task is to gather pixels into one whole, into a more integral area, which is much useful and important for future research, because we create a clearer outline of the object. The perspective of an image can serve both as a useful tool and a very strong drawback since the borders can be clearly highlighted or even erased in the image. \textbf{Here will be one two images, seg1.png and seg2.png}Typically, classic segmentation techniques may not work well for images where the boundaries between the desired features are blurred and blurred, making this work practically impossible because the pixels are too similar and the features cannot be separated or isolated.To divide the image into several parts according to the regions, have to be extremely homogeneous as the level of gray. After all, black-and-white images are easier to work with due to algorithms. As well as the color and texture of the image are also important when dividing by regions. Neighboring areas of the desired object should have very different characteristics and features because the uniformity prevents the algorithm. Also, borders of the object should be evenly distributed, and also they should not be torn or distorted. Achieving all the above characteristics gives a certain amount of difficulty, after all, how would the objects did not have their uniform or completely, they still have dire and slits, which interfere with segmentation algorithms, making a homogeneous region in a heterogeneous region. Also, our eye can also be mistaken in terms of the homogeneity of the object inside the image, because sometimes there may be holes or cuts that are not subject to our eye, so the number of pixels that we can not see, can interfere with the segmentation.[ch10]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Thresholding}\label{sec:3.4.1}
\vspace{-0.5cm}
\noindent In the methods of segmentation are the segmentation types of image in parallel. The most common and easiest method is to segment an image using a threshold. This method is based on the use of gray color. After all, we know that translating the image into a black and white contour with it is more convenient to work with than 3 color channels. This method segments the image based on image separation by saturation and grayscale. It is able to divide image according to its local threshold, which is automatic, depending on the distribution of the white and black color. And also, you can split the image using a global defect which can be defined as static and automatic and manually. It can also be noted that the threshold can be dynamic because it changes from area to area by an image.Global threshold divides the image into the desired area and its background, which he considered not similar to the area of interest to us. The local one does this by going through the image, and depending on the situation and position, select a threshold to be divided into the main part and the background part.THE most common and convenient method of threshold segmentation is - Otsu method. This method uses the interclass variance to separate areas of an image. The method is special and distinctive in that it selects only the global threshold. And the threshold is chosen by the maximum dispersion between all classes inside the image. The segmentation method has found extensive application due to the fact that it is very simple to calculate and does not require costly calculations and calculation when the algorithm itself. Also, due to a simple calculation and increases the speed of the algorithm. This algorithm can work very well when the boundaries between the object and the background are separated by an accurate and bold contrast line. In such cases, you can obtain accurate segmentation results for the image. But in the opposite case, when the boundaries are erased, this method is not able to cope, because it will not know exactly what is the object and its background. Noise can easily interfere with this method. Because the noise erases the boundaries. And uniformity also can ruin the quality of the method is the segmentation threshold.This method is effective in combined use with other methods.[1707.02051]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Clustering Methods}\label{sec:3.4.2}
\vspace{-0.5cm}
\noindent Clustering is a very powerful and unpredictable method in machine learning and computer vision. In computer vision, or rather in segmentation, it works by splitting image vectors into groups called clusters. Since clustering methods are not the same type, we can consider several types of clustering methods, but the essence of its work is based on similar points, which are very similar, and then they are grouped into separate clusters.The main problem of clustering is the correct splitting of the image into the correct sets of vectors. In this case, these vectors must be collected to have a similar value in the numbers, which means their structure must be similar. In these vectors consists mainly of the pixels of the image. Also, components can be indicators of the intensity in a given area, and 3 channel parameters that are related to each other. Texture, namely their calculated values can also be components. To associate pixels in groups, you can use any component or parameter that combines these pixels into a single value. Due to this, it is possible to find the associated objects and re-create the segmentation for the pixel count.[ch10]The\textit{ least squares error} is one of the most common measures to compare clusters that use the traditional method to break into groups. Clustering involves the process that determines the number of clusters $\kappa$. the same is created the number of groups from $C_{1}$ to $C_{\kappa}$. Each such cluster has its own personal measure of average $m_{\kappa}$. The formula of the error, said earlier, is calculated as follows:
\begin{equation}
D = {\sum\limits_{k=1}^{\kappa}} {\sum\limits_{x_i \in{C_{\kappa}}}^{\i}}{\Vert x_i - m_k \Vert}^{2}
\end{equation}

\vspace{-0.5cm}
\noindent This formula shows how close this object's data is to a particular cluster. This procedure will help you to see all the possible options for partitioning into K-th number of clusters. As a result, it will find the best option to minimize our error function D. the Disadvantage of this method is that it is impossible to calculate everything. For this reason, they find the closest number in value and divide the rest of the objects into clusters. It is also very difficult to find a global and optimal variant of the error function iteratively, for this reason, they usually resort to the random selection of clusters and selection of their mean values for further calculations. This method is called k-means clustering. There is also a method that is different from it. It is called isodata clustering. It uses a similar method of splitting and merging.This method is based on creating groups from their distance from the center of a particular cluster. Clusters are initialized randomly and iteratively go through the positions to find the most optimal point at which the error function will be reaching.[ch10]

\vspace{-0.5cm}
\noindent This method is the simplest and fastest, and most efficient for large datasets. Because it's easy to scale, it's very responsive for large datasets. The iterative nature of this method makes the optimization process easier and more convenient for calculations. But it also has a number of drawbacks, such as the number of clusters and the parameters by which these clusters need to be calculated. The iterative method is bad because every step goes through the whole sample, which is very expensive and time-consuming to calculate. There is also a problem with non-convex clusters, as they are difficult and impossible to calculate.[1707.02051]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Edge detection}\label{sec:3.4.3}
\vspace{-0.5cm}
\noindent Image edge performance greatly reduces the amount of data to be processed, but it retains the necessary information regarding the shapes of objects in place. This image explanation is easily incorporated into a large number of object recognition algorithms used in computer vision along with other image processing applications. The main property of edge detection method is its ability to remove fine edge line with a good orientation such as
well, as well as more literature on edge detection has been available in the last three decades. On the other hand, there is no General performance directory to evaluate the performance of boundary detection methods. The performance of edge detection methods is always evaluated in person and depends on its application.Edge detection is the primary tool for image segmentation. Methods of determining the boundaries to transform the source image at the image edges due to the change of the grayscale in the image. In image processing, especially in computer vision, edge detection considers the localization of important variations in gray level images and the detection of the physical and geometric properties of scene objects. This is the fundamental process of defining and outlining the object and the boundaries between objects and the background in the image. Edge detection
the most familiar approach to detect significant discontinuities in intensity values.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Histogram-based methods}\label{sec:3.4.4}
\vspace{-0.5cm}
\noindent  Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Compression-based methods}\label{sec:3.4.5}
\vspace{-0.5cm}
\noindent Soon


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Dual clustering method}\label{sec:3.4.6}
\vspace{-0.5cm}
\noindent Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Supervised Learning}\label{sec:3.5}
\vspace{-0.5cm}
\noindent Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Optimization}\label{sec:3.6}
\vspace{-0.5cm}
\noindent Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\section{Backpropagation}\label{sec:3.7}
\vspace{-0.5cm}
\noindent Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Neural Networks}\label{sec:3.8}
\vspace{-0.5cm}
\noindent Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Vanilla Neural Networks}\label{sec:3.8.1}
\vspace{-0.5cm}
\noindent Soon


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Convolutional Neural Networks}\label{sec:3.8.2}
\vspace{-0.5cm}
\noindent Soon


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Recurrent Neural Networks}\label{sec:3.8.3}
\vspace{-0.5cm}
\noindent Soon


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Capsules Neural Networks}\label{sec:3.8.4}
\vspace{-0.5cm}
\noindent Soon


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Summary}\label{sec:3.9}
\vspace{-0.5cm}
\noindent Soon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



