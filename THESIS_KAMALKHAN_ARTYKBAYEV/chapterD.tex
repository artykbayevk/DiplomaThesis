\chapter{Proposed Methods And Algorithms}\label{ch:D}
\section{Introduction}\label{sec:4.1}
\par As mentioned earlier, methods for identifying and recognizing logos on the image is quite problematic. In this Chapter, we will tell you how we came to the solution of this problem. As the basis of all the work, I decided to repeat the steps and methods of work with researchers from the DISCo laboratory[1701.02620]. Just changing the segmentation search for image segmentation, I added some layers for CNN, taking as a basis one of the most popular CNN - AlexNet, but to solve the problem and train more different networks, we will use the same CNN based on VGG16 and will try to implement ResNet. This chapter will explain in detail what frameworks and pipeline we have created to solve this problem. Also will tell about the technologies and the main dataset, which will train our CNN. 

\section{Review of Pipeline}\label{sec:4.2}
\par The problem with recognition is that we cannot know exactly where our logo will be located, which we want to recognize and find where it is. Before creating the algorithm itself, our task is to create a working dataset that will store the images and their target.The working pipeline, the first step is to get the input of the full image itself, then to carry out segmentation, filter segmented images, then CNN will hold the image through itself, in the end, there is a prediction that will give us a possible class of this logo on the image.To have the performance as high as possible in this pipeline, we use an object clause that is very review-oriented. For this reason, the CNN classifier must be created and trained to take into account that logo offered regions can contain many false positives or only part of the real logos. To solve these problems, we propose here a training structure and investigate the impact on the final efficiency of the recognition of different implementation options. \textbf{HERE WILL BE IMAGE OF MAIN PIPELINE}


\subsection{Object Segmentation Method}\label{sec:4.2.1}
\par Exhaustive search helps to find parts of the image where you want to consider the potential parts of the desired object.Although this model works well with specially selected objects, it has a number of drawbacks that significantly affect the detection of logos.After all, the search for every possible object has the ability to be impossible. To solve this, we can use selective search.To improve the whole process and the data set for testing, we can use a combined method where we will use both methods described above. Since the number of possible objects will be more and less real and possible.Diversity in this task plays an important role, as we can cover more and more possible variants of this logo in the image.Since selective search is more useful to us, it will be helpful to familiarize yourself with its dependencies.The first and most important factor is to cover as many scales as possible because the logo can be small or large. We may not warn that. After all, the situation can be quite different. Also can make problems of objects which have no clear borders, for this reason, it is necessary to look through all options of the sizes of an object.Also, it should be noted that there is no exact and general solution of searches of any objects. It is impossible to make such a general detection system. Well, at the moment of course. For this reason, you should also look at the variety of objects and their contours, which can be very important in training. Speed is an important factor when searching for possible objects in an image. After all, such systems are built to determine the objects on the camera in a short period of time.This method is exclusive in that it is possible to configure this so that it worked by concentrating on the object and not on its borders.[ssForSegmentation]


\subsection{Network architecture and training parameters}\label{sec:4.2.2}
\par To create a convenient and correct working data loader, you need to collect all the available data, using their ready-made annotation you need to crop each photo with the object, or rather with the logo. After cropping logos, you need to prepare a pair of "logo-class". Since not all logos are perfect squares, many images will have a background that will not be relevant to the logo itself. In most cases, the logos are more perpendicular.This process achieved with ground-truth of logos in images.Methods for solving these problems will be proposed to improve efficiency and achieve a good result.The first step is to try to increase subsidies by creating and generating new data that will simply be created from already having data. Generation is carried out in such a way that when creating a logo object to look from different angles and perspectives, and increasing the size of the data.To bring all images to a more comfortable and uniform color scheme, in which there will be no frequent deviations or excessive noise, you need to try to normalize the contrast and the object itself.Also, a very important idea is to create a class that would mean no logo and would mean the background itself. Due to this, CNN will know about the background and learn how to more accurately and efficiently determine the logos themselves.In the process of testing CNN, a simple image comes to the entrance, where presumably there is a logo of a company. Then the image should be segmented to possibly find any existing objects. The further task is to drive all available segments on CNN. After that, the neural network will give us an answer from its classifier.

\begin{table}[tbp]
	\centering
	\caption{CNN Architecture}
	\label{tab:arch}
	\begin{tabular}{cl}
		\toprule
		$N$ & Layers   \\
		\midrule
		1  & Conv 64 filters of $11\times 11$   \\
		2  & ReLU activation function   \\
		3  & MaxPooling with stride = 2  \\
		4  & Conv 192 filters of $5\times 5$ \\
		5  & ReLU activation function \\
		6  & MaxPooling with stride = 2 \\
		7  & Conv 384 filters of $3\times 3$ \\
		8  & ReLU activation function \\
		9  & Conv 256 filter of $3\times 3$ \\
		10 & ReLU activation function \\
		11 & Conv 256 filter of $3\times 3$ \\
		12 & ReLU activation function \\
		13 & MaxPooling with stride 2 \\ 
		14 & Dropout \\
		15 & Fully connected,size 4096 \\
		16 & ReLU activation function \\ 
		17 & Dropout \\ 
		18 & Fully connected,size 4096 \\
		19 & ReLU activation function \\
		20 & Fully connected,size number of classes \\
		21 & SoftMax function - classification \\
		
		
		\bottomrule
	\end{tabular}
\end{table}

\section{Review of Logos Dataset}\label{sec:4.3}
\par Flickr Logo s - 32 dataset is one of the largest and most extensive datasets, which is still publicly available in turn. Classes in it enough for research in this area, their 32 class, also there are samples, where logo there and is used in as a simple background. The dataset is just as unique as it is very convenient to study recognition and definition with real images where logos can appear in different positions and orientations. This dataset is divided into training, validation, and test set.The resulting images have been manually checked to make sure that the particular logo is really shown. The entire dataset is divided into three disjoint subsets $P_1$, $P_2$, and $P_3$, each containing images of all 32 classes. The first section $P_1$-the training set consists of 10 images that have been selected in such a way that they consistently show a single logo under various views with a minimum amount of background clutter. The other two sections $P_2$ (test case) and $P_3$ (test case = query case) contain 30 images per class. Unlike $P_1$, these images contain at least one instance of the logo, but in several cases, multiple instances. 

To facilitate the development of high-precision classifiers is important to assess their sensitivity to images without a logo. Therefore, both sections  $P_2$ and  $P_3$ include an additional 3,000 images downloaded from Flickr.com with "building", "nature", "people" and " friends" requests. These images are negative images and complement our dataset. A brief summary of the data is given in the table below.[1801.11417]


\begin{table}[hbp]
	\centering
	\caption{Dataset partitions/Subsets}
	\label{tab:sample12}
	\begin{tabular}{@{}lll>{\centering\arraybackslash}m{3.7cm}@{}}
		\toprule
		Partition & Description & Images & Num. of Imgs \\
		\midrule
		$P_1$ (training set) & Hand-picked images & 10 per classes  & 320 images \\
		\multirow{2}{*}{$P_2$ (validation  set)} & At least a single logo in image & 30 per classes & \multirow{2}{*}{3960 images} \\
		& Non logo images & 3000  &          \\
		\multirow{2}{*}{$P_3$ (test  set)} & At least a single logo in image & 30 per classes & \multirow{2}{*}{3960 images} \\
		& Non logo images & 3000  &          \\
		\textbf{$P_1,P_2$ and $P_3$} & Three of them disjoint & All classes & \textbf{8240 images} \\
		\bottomrule
	\end{tabular}
\end{table}




\section{Concept of Technologies and Frameworks}\label{sec:4.4}
\par PyTorch is a python package that provides two high-level features:\textbf{Tensor computation (like numpy) with strong GPU acceleration} and \textbf{Deep Neural Networks built on a tape-based autodiff system}.You can reuse your favorite python packages such as numpy, scipy and Cython to extend PyTorch when needed.At a granular level, PyTorch is a library that consists of the following components:
\begin{table}[tbp]
	\centering
	\caption{PyTorch components}
	\label{tab:sample11}
	\begin{tabular}{cl}
		\toprule
		$Component$ 			& Definition 																			\\ \midrule
		torch  					& a Tensor library like NumPy, with strong GPU support 									\\
		torch.autograd 			& a tape based automatic differentiation library that supports 							\\ 
								& all differentiable Tensor operations in torch 										\\
		torch.nn  				& a neural networks library deeply integrated with 					 					\\
								& autograd designed for maximum  flexibility 											\\
		torch.optim  			& an optimization package to be used with torch.nn with standard 						\\  
								& optimization  methods such as SGD, RMSProp, LBFGS, Adam etc.							\\
		torch.multiprocessing 	& python multiprocessing, but with magical memory sharing of torch  		`			\\ 
								& Tensors across processes. Useful for data loading and hogwild training. 				\\
		torch.utils  			& DataLoader, Trainer and other utility functions for convenience 						\\
		torch.legacy  			& legacy code that has been ported over from torch for backward compatibility reasons 	\\
		\bottomrule
	\end{tabular}
\end{table}

\noindent Usually one uses PyTorch either as:
\begin{itemize}
	\item A replacement for numpy to use the power of GPUs.
	\item A deep learning research platform that provides maximum flexibility and speed
\end{itemize}

\par PyTorch provides Tensors that can live either on the CPU or the GPU, and accelerate compute by a huge amount.\textbf{Dynamic Neural Networks: Tape based Autograd}. PyTorch has a unique way of building neural networks: using and replaying a tape recorder.Most frameworks such as TensorFlow, Theano, Caffe and CNTK have a static view of the world. One has to build a neural network, and reuse the same structure again and again. Changing the way the network behaves means that one has to start from scratch.With PyTorch, we use a technique called Reverse-mode auto-differentiation, which allows you to change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes from several research papers on this topic, as well as current and past work such as autograd, autograd, Chainer, etc.While this technique is not unique to PyTorch, it’s one of the fastest implementations of it to date. You get the best of speed and flexibility for your crazy research.PyTorch is not a Python binding into a monolothic C++ framework. It is built to be deeply integrated into Python. You can use it naturally like you would use numpy / scipy / scikit-learn etc. You can write your new neural network layers in Python itself, using your favorite libraries and use packages such as Cython and Numba. Our goal is to not reinvent the wheel where appropriate.PyTorch is designed to be intuitive, linear in thought and easy to use. When you execute a line of code, it gets executed. There isn’t an asynchronous view of the world. When you drop into a debugger, or receive error messages and stack traces, understanding them is straight-forward. The stack-trace points to exactly where your code was defined. We hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.PyTorch has minimal framework overhead. We integrate acceleration libraries such as Intel MKL and NVIDIA (CuDNN, NCCL) to maximize speed. At the core, it’s CPU and GPU Tensor and Neural Network backends (TH, THC, THNN, THCUNN) are written as independent libraries with a C99 API.
They are mature and have been tested for years.
Hence, PyTorch is quite fast – whether you run small or large neural networks.
The memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives. We’ve written custom memory allocators for the GPU to make sure that your deep learning models are maximally memory efficient. This enables you to train bigger deep learning models than before.


\section{Summary}\label{sec:4.5}
\par In this Chapter, I fully told about the approach to solving this problem. The method that will be used for segmentation is explained, as well as further work with segmented parts of the image. It was told about the architecture of CNN, also described the technology to be used. In the next Chapter, you will see the results of all the work described in this Chapter.