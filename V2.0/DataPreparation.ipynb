{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Code\n",
    "## Prepare data from directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all need libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from skimage import io, transform\n",
    "from random import randint\n",
    "\n",
    "import os, uuid, glob, warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathes for images and their annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = '../data/fl27/original'\n",
    "CROPPED_DATA_DIR = '../data/fl27/images'\n",
    "ORIGINAL_ANNOTATION = '../data/fl27/annotation.txt'\n",
    "CROPPED_ANNOTATION = '../data/fl27/crop_annotation.txt'\n",
    "\n",
    "TRAIN_SET = '../annotations/trainset.txt'\n",
    "TEST_SET = '../annotations/testset.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original images of logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = glob.glob(os.path.join(ORIGINAL_DATA_DIR, '*.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_annotation(path):\n",
    "    file = open(path, \"r\")\n",
    "    content = file.readlines()\n",
    "    new = [x.split(\" \")[:-1] for x in content]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing labels list from annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(annotaton_path):\n",
    "    arr = read_from_annotation(annotaton_path)\n",
    "    labels = []\n",
    "    for item in (arr):\n",
    "        l = item[1]\n",
    "        if l not in labels:\n",
    "            labels.append(l)\n",
    "        else:\n",
    "            continue\n",
    "    return labels\n",
    "LABELS = prepare_labels(ORIGINAL_ANNOTATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating crops and resize them for creating test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resized_crops(input_annotation, input_directory,\n",
    "                        output_annotation, output_directory):\n",
    "    annotation = read_from_annotation(input_annotation)\n",
    "    output_annotation = open(output_annotation, 'w')\n",
    "    for i, data in zip(range(len(annotation)),annotation):\n",
    "        img_name = data[0]\n",
    "        img_path = os.path.join(input_directory, img_name)\n",
    "        image = io.imread(img_path)\n",
    "        positions = data[-4:]\n",
    "        x1 = int(positions[0])\n",
    "        y1 = int(positions[1])\n",
    "        x2 = int(positions[2])\n",
    "        y2 = int(positions[3])\n",
    "\n",
    "        if x1 > x2:\n",
    "            tmp = x1\n",
    "            x1 = x2\n",
    "            x2 = tmp\n",
    "\n",
    "        if y1 > y2:\n",
    "            tmp = y1\n",
    "            y1 = y2\n",
    "            y2 = tmp\n",
    "        \n",
    "        \n",
    "            \n",
    "        target = data[1]\n",
    "        crop_resizer(image, target, x1,x2,y1,y2,output_annotation, output_directory)\n",
    "        crop_resizer(image, target, x1-40,x2,y1,y2,output_annotation, output_directory)\n",
    "        crop_resizer(image, target, x1,x2+40,y1,y2,output_annotation, output_directory)\n",
    "        crop_resizer(image, target, x1,x2,y1-40,y2,output_annotation, output_directory)\n",
    "        crop_resizer(image, target, x1,x2,y1,y2+40,output_annotation, output_directory)\n",
    "\n",
    "def crop_resizer(image,target, x1,x2,y1,y2, writer,directory):\n",
    "    crop_img = image[y1:y2, x1:x2]\n",
    "    file_name = str(uuid.uuid4().hex)+'.jpg'\n",
    "    try:\n",
    "        try:\n",
    "            resized = transform.resize(crop_img,(224, 224))\n",
    "            io.imsave(os.path.join(directory, file_name), resized)\n",
    "            note = \"{} {} \\n\".format(file_name, target)\n",
    "            writer.write(note)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    except IndexError:\n",
    "        pass\n",
    "#create_resized_crops(ORIGINAL_ANNOTATION, ORIGINAL_DATA_DIR, CROPPED_ANNOTATION, CROPPED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing images into train and test dataset, prepare SET.TXT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(crop_ann_path, out_directory, test_size = 1000):\n",
    "    train = read_from_annotation(crop_ann_path)\n",
    "    test = []\n",
    "    for i in range(test_size):\n",
    "        randIndex = randint(0,len(train)-1)\n",
    "        test.append(train[randIndex])\n",
    "        del(train[randIndex])\n",
    "\n",
    "    trainset = file(TRAIN_SET, \"w\")\n",
    "    testset = file(TEST_SET, \"w\")\n",
    "\n",
    "    for item in train:\n",
    "        tmp = \"{} {} \\n\".format(item[0], item[1])\n",
    "        trainset.write(tmp)\n",
    "    trainset.close()\n",
    "\n",
    "    for item in test:\n",
    "        tmp = \"{} {} \\n\".format(item[0], item[1])\n",
    "        testset.write(tmp)\n",
    "    testset.close()\n",
    "train_test_split(CROPPED_ANNOTATION,RESIZED_ANNOTATION,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pytorch dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main pytorch dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt_file, root):\n",
    "        self.txt_file = txt_file\n",
    "        self.root = root\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.txt_file.shape[0]\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        img_name = os.path.join(self.root, self.txt_file[id][0])\n",
    "        img = io.imread(img_name)\n",
    "        logo = int(self.txt_file[id][1])\n",
    "        image = img.transpose((2, 0, 1))\n",
    "        img = torch.FloatTensor(image)\n",
    "        return img,logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My main labels(in future I want to add new class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adidas', 'Apple', 'BMW', 'Citroen', 'Cocacola', 'DHL', 'Fedex', 'Ferrari', 'Ford', 'Google', 'Heineken', 'HP', 'Intel', 'McDonalds', 'Mini', 'Nbc', 'Nike', 'Pepsi', 'Porsche', 'Puma', 'RedBull', 'Sprite', 'Starbucks', 'Texaco', 'Unicef', 'Vodafone', 'Yahoo']\n"
     ]
    }
   ],
   "source": [
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert function from simple list into numpy array with categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_num_dataset(annotation_path, set_path):\n",
    "    arr = read_from_annotation(set_path)\n",
    "    out = []\n",
    "    for item in arr:\n",
    "        tmp = [item[0], LABELS.index(item[1])]\n",
    "        out.append(tmp)\n",
    "    out = np.array(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating main train and test set, which are suitable for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 16185 items and test size 5000 items\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_num_dataset(CROPPED_ANNOTATION, TRAIN_SET)\n",
    "test_data = prepare_num_dataset(CROPPED_ANNOTATION, TEST_SET)\n",
    "trainset = MyDataset(train_data, CROPPED_DATA_DIR)\n",
    "testset = MyDataset(test_data, CROPPED_DATA_DIR)\n",
    "print(\"Train size {} items and test size {} items\".format(len(trainset), len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Data Loaders, which send for training batches with fixed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "                                           batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Convolutional Neural Network with 27 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without any class balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize hyper parameters of CNN and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "n_classes = 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating CNN class and initialize it with number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, n_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "cnn = CNN(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr = learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                %(epoch+1, num_epochs, i+1, len(trainset)//batch_size, loss.data[0]))\n",
    "\n",
    "# Save the Trained Model\n",
    "torch.save(cnn.state_dict(), 'cnn-vol-2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing neural network on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(n_classes)\n",
    "cnn.load_state_dict(torch.load('cnn-vol-2.pt'))\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
